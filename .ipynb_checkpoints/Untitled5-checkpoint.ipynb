{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be719d0b-2be8-417f-8320-167929aa382a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ZDIPlookup.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 17\u001b[0m\n\u001b[0;32m     12\u001b[0m general_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     15\u001b[0m zazicSites\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzazicFacilities.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mZDIPlookup.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m lookupTable \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(data,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreviousVMMCSubmissions\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m general_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ZDIPlookup.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "# Initialize lists to store categorized data\n",
    "referrals_data = []\n",
    "AEs_data = []\n",
    "general_data = []\n",
    "\n",
    "\n",
    "zazicSites= pd.read_excel('zazicFacilities.xlsx')\n",
    "\n",
    "data = pd.ExcelFile('ZDIPlookup.xlsx')\n",
    "\n",
    "lookupTable = pd.read_excel(data,'previousVMMCSubmissions')\n",
    "\n",
    "general_df = pd.read_excel('test.xlsx')\n",
    "\n",
    "general_df.columns = [re.split(r'[./]', col)[-1] for col in general_df.columns]\n",
    "\n",
    "# New columns that should NOT be deleted\n",
    "columns_to_retain = [\n",
    "    'AERecordingMonth', 'AERecordingSite', 'AERecordingYear', 'aeComments', 'ae_classification', \n",
    "    'ae_type_code', 'checkMonthValidation', 'checkYearValidation', 'circumcising_cadre', 'client_age', \n",
    "    'date_ae_identified', 'mcMethod', 'vmmc_number', 'followUpTotal', 'recordingMonth', \n",
    "    'total_hiv_negative_linked_to_prep', 'total_hiv_positive_linked_to_care', 'ReferrelRecordingMonth', \n",
    "    'ReferrelRecordingSite', 'ReferrelRecordingYear', 'reason_for_referral', 'services_referred', 'facilityName', \n",
    "    'District', 'recordingMonth', 'year', 'totalAES','adverse_events', 'Site_Name', 'totalReferralstoOtherServices', 'formType','received_on', 'ageGroupsChange'\n",
    "]\n",
    "\n",
    "# Columns that must be numeric (including the new ones)\n",
    "numeric_columns = [\n",
    "    'client_age', 'fu15-19', 'fu20-24', 'fu25-29', 'fu30-34', 'fu40-44', 'fu50',\n",
    "    'total_hiv_negative_linked_to_prep', 'total_hiv_positive_linked_to_care', 'referralToOtherServices',\n",
    "    'total_mcs_referred_for_srh_services', 'total_mcs_referred_for_sti_services', 'checkifFacilityHasBeenSaved',\n",
    "    'hivNegativeNC15-19', 'hivNegativeNC20-24', 'hivNegativeNC25-29', 'hivNegativeNC30-34', 'hivNegativeNC35-39', \n",
    "    'hivNegativeNC40-44', 'hivNegativeNC45-49', 'hivNegativeNC50', 'total_surgicalDisposable', 'hivPositive30-34',\n",
    "    'hivPositiveNC15-19', 'hivPositiveNC20-24', 'hivPositiveNC25-29', 'hivPositiveNC35-39', 'hivPositiveNC40-44',\n",
    "    'hivPositiveNC45-49', 'hivPositiveNC50', 'total15-19NCHIVTested', 'total20-24NCHIVTested', 'total25-29NCHIVTested',\n",
    "    'total30-34NCHIVTested', 'total35-39NCHIVTested', 'total40-44NCHIVTested', 'total45-49NCHIVTested', \n",
    "    'total50NCHIVTested', 'total_surgicalReusable', 'totalHIVPositiveNC', 'totalhivNegativeNC', \n",
    "    'uncircumcisedClientsForHTS', 'hivNegative15-19', 'hivNegative20-24', 'hivNegative25-29', 'hivNegative30-34', \n",
    "    'hivNegative40-44', 'hivNegative50', 'total_surgicalDisposable', 'hivPositive15-19', 'hivPositive20-24','hivPositive25-29',\n",
    "    'hivPositive30-34','hivPositive35-39','hivPositive40-44','hivPositive45-49','hivPositive50',\n",
    "    'total15-19HIVTested', 'total20-24HIVTested', 'total25-29HIVTested', 'total30-34HIVTested', 'total35-39HIVTested',\n",
    "    'total40-44HIVTested', 'total45-49HIVTested', 'total50HIVTested', 'total_surgicalReusable', 'totalHIVPositive',\n",
    "    'totalHIVUntested', 'totalhivNegative', 'TotalMCsBYMethod', 'sgDisposable15-19', 'sgDisposable20-24', \n",
    "    'sgDisposable25-29', 'sgDisposable30-34', 'sgDisposable40-44', 'sgDisposable50', 'total_surgicalDisposable',\n",
    "    'sgReusable15-19', 'sgReusable20-24', 'sgReusable25-29', 'sgReusable30-34', 'sgReusable40-44', 'sgReusable50',\n",
    "    'total_surgicalReusable', 'total50ByMethod', 'totalShangringMCs', 'totalSurgicalDisposableMCs', \n",
    "    'totalSurgicalReusableMCs', 'mc15-19', 'mc20-24', 'mc25-29', 'mc30-34', 'mc35-39', 'mc40-44', 'mc45-49', \n",
    "    'mc50', 'totalMCs', 'fu35-39', 'other_referrals_in_detail', 'total_mcs_referred_to_other_services', \n",
    "    'hivNegative35-39', 'sgDisposable35-39', 'sgReusable35-39', 'shangring15-19', 'shangring20-24','shangring25-29', 'shangring30-34',\n",
    "    'shangring35-39', 'shangring40-44','shangring45-49','shangring50', 'fu45-49', \n",
    "    'hivNegative45-49', 'sgDisposable45-49', 'sgReusable45-49','AERecordingYear','high_risk_referrals_to_care'\n",
    "]\n",
    "\n",
    "# general_df['AERecordingYear'] = pd.to_numeric(general_df['AERecordingYear'])\n",
    "# Combine the two lists (retain columns that are in either columns_to_retain or numeric_columns)\n",
    "columns_to_keep = list(set(columns_to_retain + numeric_columns))\n",
    "\n",
    "# Identify missing columns\n",
    "missing_columns = [col for col in columns_to_keep if col not in general_df.columns]\n",
    "\n",
    "# Add missing columns to the DataFrame and assign zero\n",
    "for col in missing_columns:\n",
    "    general_df[col] = 0\n",
    "\n",
    "# Drop the columns that are not in the columns_to_keep list\n",
    "# Sort the columns alphabetically in both DataFrames\n",
    "\n",
    "# For the 'general_df', sort the columns alphabetically\n",
    "general_df_sorted = general_df[sorted(general_df[columns_to_keep])]\n",
    "\n",
    "# For the AE-specific columns, we can do the same\n",
    "ae_columns = [\n",
    "    'aeComments', 'ae_type_code', 'date_ae_identified', 'AERecordingYear', 'AERecordingSite', \n",
    "    'client_age', 'circumcising_cadre', 'ae_classification', 'AERecordingMonth', 'mcMethod','vmmc_number'\n",
    "]\n",
    "\n",
    "\n",
    "referrals_columns =['ReferrelRecordingMonth', \n",
    "    'ReferrelRecordingSite', 'ReferrelRecordingYear', 'services_referred','reason_for_referral']\n",
    "\n",
    "\n",
    "\n",
    "other_referrals = []\n",
    "ae_data_df_sorted = general_df[ae_columns][sorted(ae_columns)]\n",
    "ae_data_df_sorted = ae_data_df_sorted[ae_data_df_sorted['AERecordingMonth'].notna()]\n",
    "\n",
    "referralsDF_sorted = general_df[referrals_columns][sorted(referrals_columns)]\n",
    "referralsDF_sorted = referralsDF_sorted[referralsDF_sorted['ReferrelRecordingMonth'].notna()]\n",
    "\n",
    "# Function to flatten the nested referral data\n",
    "def flatten_referral_data(referral_list):\n",
    "    flattened_referrals = []\n",
    "    \n",
    "    # Loop through each referral in the list\n",
    "    for referral in referral_list:\n",
    "        flattened_referral = {}\n",
    "        \n",
    "        # Flatten the first level of referral data\n",
    "        for key, value in referral.items():\n",
    "            if isinstance(value, dict):\n",
    "                # If the value is a nested dictionary, flatten it\n",
    "                for nested_key, nested_value in value.items():\n",
    "                    flattened_referral[f\"{key}_{nested_key}\"] = nested_value\n",
    "            else:\n",
    "                flattened_referral[key] = value\n",
    "        \n",
    "        flattened_referrals.append(flattened_referral)\n",
    "    \n",
    "    return flattened_referrals\n",
    "\n",
    "\n",
    "\n",
    "# Function to unpack nested 'question1_question5' field\n",
    "def unpack_detailedField(df, column):\n",
    "    if column  in df.columns:\n",
    "        # Unpack the dictionary inside 'question1_question5' into separate columns\n",
    "        question_fields = df[column].apply(pd.Series)\n",
    "        \n",
    "        # Merge the unpacked fields back into the main DataFrame\n",
    "        df = pd.concat([df, question_fields], axis=1)\n",
    "        \n",
    "        # Drop the original 'question1_question5' column if no longer needed\n",
    "        df.drop(column, axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# Extract the referrals from 'other_referrals_in_detail' column referrals_data = []\n",
    "singleReferrals =[]\n",
    "# Loop through each row and check if 'other_referrals_in_detail' is a valid list\n",
    "for idx, row in general_df.iterrows():\n",
    "    referral_list = row['other_referrals_in_detail']\n",
    "    \n",
    "    # Check if the value is a list and not NaN\n",
    "    if isinstance(referral_list, list):\n",
    "        # Flatten the referral data\n",
    "        flattened_referrals = flatten_referral_data(referral_list)\n",
    "        for ref in flattened_referrals:\n",
    "            ref['District'] = row['District']  # Add the District to each referral record\n",
    "            referrals_data.append(ref)\n",
    "    else:\n",
    "        # Handle cases where referral_list is not valid\n",
    "        if not pd.isna(row['ReferrelRecordingMonth']):  # Check if 'ReferrelRecordingMonth' is not NaN\n",
    "            _object = {\n",
    "                'ReferrelRecordingMonth': row['ReferrelRecordingMonth'], \n",
    "                'ReferrelRecordingSite': row['ReferrelRecordingSite'], \n",
    "                'ReferrelRecordingYear': row['ReferrelRecordingYear'],\n",
    "                'District': row['District'],\n",
    "                'reason_for_referral':row['reason_for_referral'],\n",
    "                'services_referred':row['services_referred']\n",
    "            }\n",
    "            singleReferrals.append(_object)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "aes_data =[]\n",
    "singleAEs = []\n",
    "for idx, row in general_df.iterrows():\n",
    "    ae_list = row['adverse_events']\n",
    "    \n",
    "    # Check if the value is a list and not NaN\n",
    "    if isinstance(ae_list, list) and not pd.isna(ae_list).any():  # Use .any() to check the entire list\n",
    "        flattened_aes = flatten_referral_data(ae_list)\n",
    "        for ref in flattened_aes:\n",
    "            ref['District'] = row['District']  # Add the District to each referral record\n",
    "            aes_data.append(ref)\n",
    "\n",
    "    else:\n",
    "        if not pd.isna(row['AERecordingMonth']):\n",
    "            _object = {\n",
    "                'AERecordingMonth':row['AERecordingMonth'],\n",
    "                'AERecordingSite':row['AERecordingSite'],\n",
    "                'AERecordingYear':row['AERecordingYear'],\n",
    "                'District':row['District'],\n",
    "                'aeComments':row['aeComments'],\n",
    "                'ae_classification':row['ae_classification'],\n",
    "                'ae_type_code':row['ae_type_code'],\n",
    "                'circumcising_cadre':row['circumcising_cadre'],\n",
    "                'client_age':row['client_age'],\n",
    "                'date_ae_identified':row['date_ae_identified'],\n",
    "                'mcMethod':row['mcMethod'],\n",
    "                'vmmc_number':row['vmmc_number']\n",
    "            }\n",
    "            singleAEs.append(_object)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "# Convert the flattened referrals data into a DataFrame\n",
    "\n",
    "referrals_df = pd.DataFrame(referrals_data)\n",
    "\n",
    "# convert the flattened aes data into a df\n",
    "\n",
    "ae_df = pd.DataFrame(aes_data)\n",
    "\n",
    "# Unpack the 'question1_question5' field\n",
    "referrals_df = unpack_detailedField(referrals_df,'question1_question5')\n",
    "\n",
    "ae_df = unpack_detailedField(ae_df,'question3_question1')\n",
    "\n",
    "ae_df = unpack_detailedField(ae_df,'question1')\n",
    "\n",
    "ae_df = ae_df.rename(columns={\n",
    "    'question3_AERecordingMonth': 'AERecordingMonth',\n",
    "    'question3_AERecordingSite': 'AERecordingSite',\n",
    "    'question3_AERecordingYear': 'AERecordingYear'\n",
    "})\n",
    "\n",
    "print(ae_df)\n",
    "\n",
    "if len(singleReferrals)>0:\n",
    "    tempRefDF = pd.DataFrame(singleReferrals)\n",
    "    referrals_df = pd.concat([referrals_df,tempRefDF])\n",
    "\n",
    "if len(singleAEs)>0:\n",
    "    tempRefDF = pd.DataFrame(singleAEs)\n",
    "    ae_df = pd.concat([ae_df,tempRefDF])\n",
    "\n",
    "\n",
    "if not referrals_df.empty:\n",
    "    try:\n",
    "        referrals_df = referrals_df.drop(columns = ['question1_cancelthisReferralReport',0]).drop_duplicates()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "if not ae_df.empty:\n",
    "    try:\n",
    "        ae_df = ae_df.drop(columns = ['checkMonthValidation','checkYearValidation']).drop_duplicates()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "general_df_sorted = general_df_sorted.drop(columns =['adverse_events','other_referrals_in_detail']).drop_duplicates()\n",
    "\n",
    "\n",
    "zazicSites_unique = zazicSites.drop_duplicates(subset='facilityName')\n",
    "\n",
    "\n",
    "general_df_sorted = general_df_sorted.loc[:, ~general_df_sorted.columns.duplicated(keep='last')]\n",
    "\n",
    "# # Merge to bring in facilityType from zazicSites_unique\n",
    "# general_df_sorted = general_df_sorted.merge(zazicSites_unique[['facilityName', 'facilityType']], \n",
    "#                                             on='facilityName', \n",
    "#                                             how='left')\n",
    "\n",
    "# Step 1: Identify the latest 'correction' row for each facilityName, recordingMonth, and year\n",
    "latest_correction_idx = general_df_sorted[general_df_sorted['formType'] == 'correction'].groupby(['facilityName', 'recordingMonth', 'year'])['received_on'].idxmax()\n",
    "\n",
    "# Step 2: Create a dictionary to store the latest correction rows\n",
    "latest_corrections = general_df_sorted.loc[latest_correction_idx]\n",
    "\n",
    "age_groups = ['15-19_yrs', '20-24_yrs', '25-29_yrs', '30-34_yrs', '35-39_yrs', '40-44_yrs', '45-49_yrs', '50+_yrs']\n",
    "\n",
    "# Columns to update for each age group\n",
    "columns_to_update = ['mc', 'sgDisposable', 'sgReusable', 'shangring', 'fu', 'hivPositive', 'hivNegative']\n",
    "\n",
    "# DataFrame to store the final results\n",
    "final_df = general_df_sorted.copy()\n",
    "\n",
    "# Step 1: Iterate through submission rows\n",
    "for idx, row in general_df_sorted[general_df_sorted['formType'] == 'submission'].iterrows():\n",
    "    facility, month, year = row['facilityName'], row['recordingMonth'], row['year']\n",
    "\n",
    "    # Step 2: Find corresponding correction row\n",
    "    correction_row = latest_corrections[\n",
    "        (latest_corrections['facilityName'] == facility) &\n",
    "        (latest_corrections['recordingMonth'] == month) &\n",
    "        (latest_corrections['year'] == year)\n",
    "    ]\n",
    "\n",
    "    if not correction_row.empty:  # If a correction row exists\n",
    "        # Step 3: Check if a row exists in lookupTable\n",
    "        lookup_match = lookupTable[\n",
    "            (lookupTable['facilityName'] == facility) &\n",
    "            (lookupTable['recordingMonth'] == month) &\n",
    "            (lookupTable['year'] == year)\n",
    "        ]\n",
    "\n",
    "        if not lookup_match.empty:  \n",
    "            # Apply corrections to lookupTable row instead of submission row\n",
    "            target_idx = lookup_match.index[0]  # Get index of matched row\n",
    "            target_df = lookupTable  # Apply updates to lookupTable\n",
    "            \n",
    "            # Step 4: Update the matched row in lookupTable\n",
    "            age_groups_change = correction_row['ageGroupsChange'].values[0]\n",
    "            for age_group in age_groups:\n",
    "                if age_group in age_groups_change:\n",
    "                    for column_prefix in columns_to_update:\n",
    "                        column_name = f'{column_prefix}{age_group.split(\"_\")[0]}'\n",
    "                        target_df.at[target_idx, column_name] = correction_row[column_name].values[0]\n",
    "\n",
    "            # Remove the submission row from final dataframe\n",
    "            final_df.drop(index=idx, inplace=True)\n",
    "\n",
    "            # Add the updated row from lookupTable to final dataframe\n",
    "            final_df = pd.concat([final_df, lookupTable.loc[[target_idx]]], ignore_index=True)\n",
    "\n",
    "        else:\n",
    "            # No match in lookupTable, apply changes to the original submission row\n",
    "            age_groups_change = correction_row['ageGroupsChange'].values[0]\n",
    "            for age_group in age_groups:\n",
    "                if age_group in age_groups_change:\n",
    "                    for column_prefix in columns_to_update:\n",
    "                        column_name = f'{column_prefix}{age_group.split(\"_\")[0]}'\n",
    "                        final_df.at[idx, column_name] = correction_row[column_name].values[0]\n",
    "\n",
    "# Step 5: Remove correction rows from final dataframe\n",
    "final_df = final_df[~final_df.index.isin(latest_corrections.index)]\n",
    "\n",
    "# Reset index to maintain consistency\n",
    "final_df.reset_index(drop=True, inplace=True)\n",
    "                \n",
    "# Now save the DataFrame to Excel\n",
    "with pd.ExcelWriter('dataTest.xlsx', engine='xlsxwriter') as writer:\n",
    "    # Save the sorted general data to the first sheet\n",
    "    general_df_sorted.drop_duplicates().to_excel(writer, sheet_name='Statistics', index=False)\n",
    "    \n",
    "    # Save the sorted AE data to a new sheet\n",
    "    ae_df.drop_duplicates().to_excel(writer, sheet_name='AEs', index=False)\n",
    "    \n",
    "    # Save the flattened referrals data to a new sheet\n",
    "    referrals_df.drop_duplicates().to_excel(writer, sheet_name='Referrals', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
